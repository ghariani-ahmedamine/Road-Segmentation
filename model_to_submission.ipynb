{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "9932e7b7-e8ce-48e0-9c85-91be641a9d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import cv2\n",
    "\n",
    "foreground_threshold = 0.25 # percentage of pixels > 1 required to assign a foreground label to a patch\n",
    "\n",
    "# assign a label to a patch\n",
    "def patch_to_label(patch):\n",
    "    df = np.mean(patch)\n",
    "    if df > foreground_threshold:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def mask_to_submission_strings(image_filename):\n",
    "    \"\"\"Reads a single image and outputs the strings that should go into the submission file\"\"\"\n",
    "    img_number = int(re.search(r\"\\d+\", image_filename).group(0))\n",
    "    im = mpimg.imread(image_filename)\n",
    "    patch_size = 16\n",
    "    for j in range(0, im.shape[1], patch_size):\n",
    "        for i in range(0, im.shape[0], patch_size):\n",
    "            patch = im[i:i + patch_size, j:j + patch_size]\n",
    "            label = patch_to_label(patch)\n",
    "            yield(\"{:03d}_{}_{},{}\".format(img_number, j, i, label))\n",
    "\n",
    "\n",
    "def masks_to_submission(submission_filename, *image_filenames):\n",
    "    \"\"\"Converts images into a submission file\"\"\"\n",
    "    with open(submission_filename, 'w') as f:\n",
    "        f.write('id,prediction\\n')\n",
    "        for fn in image_filenames[0:]:\n",
    "            f.writelines('{}\\n'.format(s) for s in mask_to_submission_strings(fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "4c719c95-ae67-4b23-a672-68d2915f8231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/training/groundtruth/satImage_001.png\n",
      "data/training/groundtruth/satImage_002.png\n",
      "data/training/groundtruth/satImage_003.png\n",
      "data/training/groundtruth/satImage_004.png\n",
      "data/training/groundtruth/satImage_005.png\n",
      "data/training/groundtruth/satImage_006.png\n",
      "data/training/groundtruth/satImage_007.png\n",
      "data/training/groundtruth/satImage_008.png\n",
      "data/training/groundtruth/satImage_009.png\n",
      "data/training/groundtruth/satImage_010.png\n",
      "data/training/groundtruth/satImage_011.png\n",
      "data/training/groundtruth/satImage_012.png\n",
      "data/training/groundtruth/satImage_013.png\n",
      "data/training/groundtruth/satImage_014.png\n",
      "data/training/groundtruth/satImage_015.png\n",
      "data/training/groundtruth/satImage_016.png\n",
      "data/training/groundtruth/satImage_017.png\n",
      "data/training/groundtruth/satImage_018.png\n",
      "data/training/groundtruth/satImage_019.png\n",
      "data/training/groundtruth/satImage_020.png\n",
      "data/training/groundtruth/satImage_021.png\n",
      "data/training/groundtruth/satImage_022.png\n",
      "data/training/groundtruth/satImage_023.png\n",
      "data/training/groundtruth/satImage_024.png\n",
      "data/training/groundtruth/satImage_025.png\n",
      "data/training/groundtruth/satImage_026.png\n",
      "data/training/groundtruth/satImage_027.png\n",
      "data/training/groundtruth/satImage_028.png\n",
      "data/training/groundtruth/satImage_029.png\n",
      "data/training/groundtruth/satImage_030.png\n",
      "data/training/groundtruth/satImage_031.png\n",
      "data/training/groundtruth/satImage_032.png\n",
      "data/training/groundtruth/satImage_033.png\n",
      "data/training/groundtruth/satImage_034.png\n",
      "data/training/groundtruth/satImage_035.png\n",
      "data/training/groundtruth/satImage_036.png\n",
      "data/training/groundtruth/satImage_037.png\n",
      "data/training/groundtruth/satImage_038.png\n",
      "data/training/groundtruth/satImage_039.png\n",
      "data/training/groundtruth/satImage_040.png\n",
      "data/training/groundtruth/satImage_041.png\n",
      "data/training/groundtruth/satImage_042.png\n",
      "data/training/groundtruth/satImage_043.png\n",
      "data/training/groundtruth/satImage_044.png\n",
      "data/training/groundtruth/satImage_045.png\n",
      "data/training/groundtruth/satImage_046.png\n",
      "data/training/groundtruth/satImage_047.png\n",
      "data/training/groundtruth/satImage_048.png\n",
      "data/training/groundtruth/satImage_049.png\n",
      "data/training/groundtruth/satImage_050.png\n"
     ]
    }
   ],
   "source": [
    "submission_filename = 'dummy_submission.csv'\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = 'data/training/groundtruth/satImage_' + '%.3d' % i + '.png'\n",
    "    print (image_filename)\n",
    "    image_filenames.append(image_filename)\n",
    "masks_to_submission(submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "292b7f52-35a9-4e83-a1a6-93d64f92f77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model \n",
    "from keras.models import load_model\n",
    "model = load_model('best_unet_dice_batch1_4depth_16base_400_interpol.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "1470d416-13e9-4a7f-9bc2-6a963dcfb7fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data/test_set_images/test_1/test_1.png',\n",
       " 'data/test_set_images/test_2/test_2.png',\n",
       " 'data/test_set_images/test_3/test_3.png',\n",
       " 'data/test_set_images/test_4/test_4.png',\n",
       " 'data/test_set_images/test_5/test_5.png',\n",
       " 'data/test_set_images/test_6/test_6.png',\n",
       " 'data/test_set_images/test_7/test_7.png',\n",
       " 'data/test_set_images/test_8/test_8.png',\n",
       " 'data/test_set_images/test_9/test_9.png',\n",
       " 'data/test_set_images/test_10/test_10.png',\n",
       " 'data/test_set_images/test_11/test_11.png',\n",
       " 'data/test_set_images/test_12/test_12.png',\n",
       " 'data/test_set_images/test_13/test_13.png',\n",
       " 'data/test_set_images/test_14/test_14.png',\n",
       " 'data/test_set_images/test_15/test_15.png',\n",
       " 'data/test_set_images/test_16/test_16.png',\n",
       " 'data/test_set_images/test_17/test_17.png',\n",
       " 'data/test_set_images/test_18/test_18.png',\n",
       " 'data/test_set_images/test_19/test_19.png',\n",
       " 'data/test_set_images/test_20/test_20.png',\n",
       " 'data/test_set_images/test_21/test_21.png',\n",
       " 'data/test_set_images/test_22/test_22.png',\n",
       " 'data/test_set_images/test_23/test_23.png',\n",
       " 'data/test_set_images/test_24/test_24.png',\n",
       " 'data/test_set_images/test_25/test_25.png',\n",
       " 'data/test_set_images/test_26/test_26.png',\n",
       " 'data/test_set_images/test_27/test_27.png',\n",
       " 'data/test_set_images/test_28/test_28.png',\n",
       " 'data/test_set_images/test_29/test_29.png',\n",
       " 'data/test_set_images/test_30/test_30.png',\n",
       " 'data/test_set_images/test_31/test_31.png',\n",
       " 'data/test_set_images/test_32/test_32.png',\n",
       " 'data/test_set_images/test_33/test_33.png',\n",
       " 'data/test_set_images/test_34/test_34.png',\n",
       " 'data/test_set_images/test_35/test_35.png',\n",
       " 'data/test_set_images/test_36/test_36.png',\n",
       " 'data/test_set_images/test_37/test_37.png',\n",
       " 'data/test_set_images/test_38/test_38.png',\n",
       " 'data/test_set_images/test_39/test_39.png',\n",
       " 'data/test_set_images/test_40/test_40.png',\n",
       " 'data/test_set_images/test_41/test_41.png',\n",
       " 'data/test_set_images/test_42/test_42.png',\n",
       " 'data/test_set_images/test_43/test_43.png',\n",
       " 'data/test_set_images/test_44/test_44.png',\n",
       " 'data/test_set_images/test_45/test_45.png',\n",
       " 'data/test_set_images/test_46/test_46.png',\n",
       " 'data/test_set_images/test_47/test_47.png',\n",
       " 'data/test_set_images/test_48/test_48.png',\n",
       " 'data/test_set_images/test_49/test_49.png',\n",
       " 'data/test_set_images/test_50/test_50.png']"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get test images names\n",
    "test_img_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = 'data/test_set_images/test_' + '%.1d' % i + '/test_'+ '%.1d' % i + '.png'\n",
    "    test_img_filenames.append(image_filename)\n",
    "test_img_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "817cfd6f-ef2b-462a-b622-6078afcbea2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/Users/ahmednourachiche/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/ahmednourachiche/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ahmednourachiche/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/ahmednourachiche/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/Users/ahmednourachiche/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ahmednourachiche/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 400, 400, 3), found shape=(None, 608, 608, 3)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/l5/cs55qw2j2hq1gh73rh2_bhj00000gn/T/ipykernel_24773/1343874791.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img_filenames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m41\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m255.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.557\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m121\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/tensorflow/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1127\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1128\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1129\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/Users/ahmednourachiche/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1621, in predict_function  *\n        return step_function(self, iterator)\n    File \"/Users/ahmednourachiche/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1611, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/Users/ahmednourachiche/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1604, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/Users/ahmednourachiche/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/training.py\", line 1572, in predict_step\n        return self(x, training=False)\n    File \"/Users/ahmednourachiche/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/utils/traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/Users/ahmednourachiche/miniforge3/envs/tensorflow/lib/python3.9/site-packages/keras/engine/input_spec.py\", line 263, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model_1\" is incompatible with the layer: expected shape=(None, 400, 400, 3), found shape=(None, 608, 608, 3)\n"
     ]
    }
   ],
   "source": [
    "#for j in range(0,50):\n",
    "img = cv2.imread(test_img_filenames[41]) / 255.\n",
    "img =np.expand_dims(img, 0)\n",
    "prediction = (model.predict(img)[0,:,:,0] > 0.557).astype(np.uint8)\n",
    "plt.subplot(121)\n",
    "plt.imshow(img[0,:,:,:])\n",
    "plt.subplot(122)\n",
    "plt.imshow(prediction, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4af7667f-45f3-469a-ad0b-47bb4305688a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 608, 608, 3)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_imgs = np.array([cv2.imread(test_img_filenames[i]) / 255. for i in range (0,50)])\n",
    "test_imgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "4823a0de-10aa-4354-8aea-a219ec499d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.cm as cm\n",
    "for i in range(1,51):\n",
    "    img = cv2.resize(test_imgs[i-1],(400,400), interpolation=cv2.INTER_NEAREST) \n",
    "    img = np.expand_dims(img, 0)\n",
    "    prediction = (model.predict(img)[0,:,:,0]).astype(np.uint8)\n",
    "    filename = 'predictions/test_' + '%.1d' % i+ '.png'\n",
    "    plt.imsave(filename, prediction.reshape(400,400), cmap=cm.gray)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "609a31bc-b935-42d3-b3e6-d8b540d8a815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions/test_1.png\n",
      "predictions/test_2.png\n",
      "predictions/test_3.png\n",
      "predictions/test_4.png\n",
      "predictions/test_5.png\n",
      "predictions/test_6.png\n",
      "predictions/test_7.png\n",
      "predictions/test_8.png\n",
      "predictions/test_9.png\n",
      "predictions/test_10.png\n",
      "predictions/test_11.png\n",
      "predictions/test_12.png\n",
      "predictions/test_13.png\n",
      "predictions/test_14.png\n",
      "predictions/test_15.png\n",
      "predictions/test_16.png\n",
      "predictions/test_17.png\n",
      "predictions/test_18.png\n",
      "predictions/test_19.png\n",
      "predictions/test_20.png\n",
      "predictions/test_21.png\n",
      "predictions/test_22.png\n",
      "predictions/test_23.png\n",
      "predictions/test_24.png\n",
      "predictions/test_25.png\n",
      "predictions/test_26.png\n",
      "predictions/test_27.png\n",
      "predictions/test_28.png\n",
      "predictions/test_29.png\n",
      "predictions/test_30.png\n",
      "predictions/test_31.png\n",
      "predictions/test_32.png\n",
      "predictions/test_33.png\n",
      "predictions/test_34.png\n",
      "predictions/test_35.png\n",
      "predictions/test_36.png\n",
      "predictions/test_37.png\n",
      "predictions/test_38.png\n",
      "predictions/test_39.png\n",
      "predictions/test_40.png\n",
      "predictions/test_41.png\n",
      "predictions/test_42.png\n",
      "predictions/test_43.png\n",
      "predictions/test_44.png\n",
      "predictions/test_45.png\n",
      "predictions/test_46.png\n",
      "predictions/test_47.png\n",
      "predictions/test_48.png\n",
      "predictions/test_49.png\n",
      "predictions/test_50.png\n"
     ]
    }
   ],
   "source": [
    "submission_filename = 'trial_2.csv'\n",
    "image_filenames = []\n",
    "for i in range(1, 51):\n",
    "    image_filename = 'predictions/test_' + '%.1d' % i+ '.png'\n",
    "    print (image_filename)\n",
    "    image_filenames.append(image_filename)\n",
    "masks_to_submission(submission_filename, *image_filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84060c8b-8a6e-4022-aef5-c879ab1628a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
